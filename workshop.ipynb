{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RacingAI ROS Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by opening up the Code editor, and let's look at our initial file structure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll build move into our workspace, build our package, and update our environment.\n",
    "\n",
    "```\n",
    "cd ros2_ws\n",
    "colcon build --symlink-install\n",
    "source install/setup.bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run our packages launch file\n",
    "\n",
    "```\n",
    "ros2 launch my_bot launch_sim.launch.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the topics being published\n",
    "\n",
    "```\n",
    "ros2 topic list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get info about a particular topic using\n",
    "\n",
    "```\n",
    "ros2 topic info <topic-name>\n",
    "```\n",
    "\n",
    "Or listen to it by using\n",
    "\n",
    "```\n",
    "ros2 topic echo <topic-name>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another terminal, let's try running our perception Node\n",
    "\n",
    "```\n",
    "cd ros2_ws\n",
    "source install/setup.bash\n",
    "ros2 run my_bot perception\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't do much yet! Let's change that. We can start by installing some dependencies\n",
    "\n",
    "```\n",
    "pip3 install -r ~/ros2_ws/src/my_bot/requirements.txt -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some of our libraries, and add a basic subscriber to the camera\n",
    "\n",
    "```\n",
    "...\n",
    "from sensor_msgs.msg import Image\n",
    "...\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.subscription = self.create_subscription(\n",
    "            Image,\n",
    "            '/camera/image_raw',\n",
    "            self.listener_callback,\n",
    "            1)\n",
    "\n",
    "    def listener_callback(self, msg):\n",
    "        self.get_logger().info('Received image with size {}x{}'.format(msg.width, msg.height))\n",
    "...\n",
    "```\n",
    "\n",
    "Now if we run it again, we should get some info about the received images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some basic parsing and viewing of the images\n",
    "\n",
    "```\n",
    "...\n",
    "import cv2\n",
    "import cv_bridge\n",
    "...\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.bridge = cv_bridge.CvBridge()\n",
    "...\n",
    "    def listener_callback(self, msg):\n",
    "        ...\n",
    "        cv_image = self.bridge.imgmsg_to_cv2(\n",
    "            msg, desired_encoding='passthrough')\n",
    "        cv_image = cv2.cvtColor(cv_image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow('Image window', cv_image)\n",
    "        cv2.waitKey(1)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to start doing some real perception.\n",
    "\n",
    "In the last workshop, we trained a FasterRCNN model. However, this turned out to be [too slow on machines that don't have a good GPU](https://colab.research.google.com/drive/1PCTSamO_xxDjChp7QYkkyXAT-XDnuQLD?usp=sharing).\n",
    "\n",
    "[YOLOv8](https://github.com/ultralytics/ultralytics) is the current state of the art, and [has since been trained for cone detection as well](https://colab.research.google.com/drive/1GZZFM5Z363KUtCnkUrznX19M9gGmfTca?usp=sharing). We can download the YOLOv8 model by running this script\n",
    "\n",
    "```\n",
    "python3 ~/ros2_ws/src/my_bot/data/pull_cone_detector.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run it on our images\n",
    "\n",
    "```\n",
    "...\n",
    "from ultralytics import YOLO\n",
    "...\n",
    "    def __init__(self):\n",
    "        super().__init__('perception')\n",
    "        self.load_model()\n",
    "    ...\n",
    "    def listener_callback(self, msg):\n",
    "        ...\n",
    "        results = self.model([cv_image])\n",
    "        res_plotted = results[0].plot()\n",
    "        cv2.imshow('Image window', res_plotted)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.get_logger().info('Loading cone detector model')\n",
    "        self.model = YOLO(\"/home/user/ros2_ws/src/my_bot/data/cone-detector-yolov8.pt\")\n",
    "        self.get_logger().info('Model loaded!')\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when we run our perception node, the inference is really slow. Why?\n",
    "\n",
    "If we take a look at the processes running using `top`, we can see that Gazebo uses a lot of CPU. Now that we've taken a look at it, let's run it in the background to save CPU.\n",
    "\n",
    "```\n",
    "ros2 launch my_bot launch_sim.launch.py gui:=false\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have time remaining, let's have a go at [figuring out how far away the cones are](https://pyimagesearch.com/2015/01/19/find-distance-camera-objectmarker-using-python-opencv/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
